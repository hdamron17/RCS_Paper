# Robotic Control Systems Personal Essay

## Course Overview

The Robotic Control Systems (RCS) course is a computer science and engineering hybrid course taught by senior student, Brennan Cain in the 2017 spring semester at GSSM. The course focused on the software aspect of autonomous robotics. Through the course of the semester, we used the ROS infrastructure to connect with sensors and the drive train aboard an RC-sized robot in order to complete various tasks autonomously.

## The Robot

The robot was equipt with multiple sensors to permit more autonomous capabilities. The LiDAR (Light Detection And Ranging) system uses the time for laser pulses to return to the source in relation to the speed of light to calclulate distances with high precision. That laser is then rotated about an axis to detect the distances in multiple directions. The LiDAR used abord our robot had a field of view of 270 degrees with 1081 points in each scan. Although some LiDAR systems have multiple lasers to produce three dimensional scans, ours only detected a single horizontal disk at the height of the robot. The robot also utilized a ZED passive stereo camera for use in computer vision and distance detection of objects outside the horizontal disk detected by LiDAR. Passive stereo detects recognizable objects in two images taken from some distance apart then uses geometry to calculate distances of those recognizable objects based on the distance between them in each image. The robot uses odometry to detect wheel rotations and an inertial measurement unit (IMU) sensor to detect movement based on accelerations. The Jetson was the supercomputer onboard the robot for computing responses and communicating with hardware. The Jetson supercomputer has 256 processor cores - 255 for general purpose computing and one for core coordination. Because the Jetson has such strong parallel computing capabilities, we were able to complete many tasks simultaneously. 

## Robotic Operating System (ROS)

ROS is not actually an operating system, but a tool built in Linux to coordinate tasks in parrallel. ROS tasks are completed by nodes which can publish and subscribe to topics. Each message transmits a certain message type. Publishers put information in the queue of a specific topic while subscribers pull that information from the queue and react accordingly. ROS is beneficial to robot programming because unlike most applications, robots must complete many tasks simultaneously and react to new information immediately. Nodes can be publishers on multiple topics and subscribers to multiple topics, such that instead of completing a task by calling a function and waiting for its return, a node can subscribe to a topic to receive parameters and publish the results to another topic when it finishes. This allows the completion of tasks without hanging while waiting for results.

## Wall Following

The first task in the course was to follow a wall at a constant distance using LiDAR scans. We completed it through two methods: bang-bang and a PID controller.

### Bang Bang

The bang-bang controller was used first because of its shear simplicity. Using a slice of LiDAR scan on the left or right side of the robot is used to find distance to the wall. If that distance is greater than the goal, it turns toward the wall, else it turns away from the way. We also implemented a version which includes a small buffer zone in which the robot drives straight when close to the goal. This algorithm keeps the robot on average at the goal, but because it turns toward the goal at the same rate no matter how large the error is, the bang bang controller tends to produce an oscillating motion which is not ideal.

### Proportional Integral Differential (PID)

The PID controller is designed to produce the ideal goal maintainment without the oscillation produced by a bang-bang controller. It is composed of three aspects of error multiplied by respective constants to produce the amount of change. The proportional (P) error is actual error and is used directly in computing the change amount. The integral (I) error uses history of error to account for steady state error. For example, if the robot is consistently right of the goal for some reason, the integral constant will adjust to minimize that constant error. The differential (D) error uses the change of error to prevent overshooting the goal so the robot does not begin oscillating around the goal. The differential aspect of the controller acts like dampenning on an oscillating pendulum to reduce simple harmonic motion. Such a PID controller was used initially for wall following only, but it was later expanded to many other applications.

## Free Space Exploration with Potential Field Algorithm

The next task was to navigate through free space while avoiding obstacles. Using LiDAR again, we considered each point in the LiDAR scan to be a "charge" which repelled the robot. Then using a modified version of Coulomb's law, F = k/r^2, each point applied a force against the robot. The x and y components of that force were then used to steer left/right and control speed, respectively. Because the LiDAR does not scan behind the robot, another force was applied from behind the robot to push the robot forward when there are no obstacles in its way. In the PID wall following algorithm, we required a safety controller to prevent the robot from colliding with objects in front of it, but in the potential field algorithm, the repulsion calculated in the algorithm was satisfactory in preventing obstacle collisions in *most* cases.

## Computer Vision and Object Following

The third task was to detect an object and follow it in direction and speed. To detect the object we started by detecting a tennis ball in static images using the Python API to OpenCV, a powerful computer vision library. To detect the tennis ball, we designated a range of colors to accept using HSV. HSV is a color representation scheme like RGB or BGR but instead of using the amount of each color, it uses hue - which base color it is, saturation - the amount of color, and value - the brightness of the color. We used HSV because it is easier to fine-tune as each variable acts mostly independently of the other two. Using the HSV range, the image is converted to a boolean mask of each pixel within or outside of the range. This image is then blurred using a Gaussian blur to reduce the separation of color sections because of small divisions. The blurred image is eroded, essentially the opposite of a blur, to recreate the sharpness of the image. Using OpenCV's contour detection algorithm, we found the contour of largst area and declared that the object of interest. Our computer vision worked in the end, but because of changes in lighting, etc., the HSV ranges required extensive manual tuning which would reduce its feasibility for commercial use. Once we were able to detect the tennis ball in a still image, we ported our algorithm to a ROS node to detect in real time. Our next goal was to use this computer vision to follow an orange sheet of paper. We were quickly able to use the number of pixels away from the center of the image for the steering error, but distance error propose more of a challenge. To get the depth, we used the location in one camera to index the depth map produced by the ZED camera. Because the depth map is not always complete, we used the minimum of a range around the object. This distance was compared to a goal distance to produce the speed error. A PID controller was used for both speed and steering to maintain a constant distance behind the object.

## Simultaneous Localization And Mapping (SLAM)

For our final project, we used SLAM to map the upstairs academic hallway. The SLAM algorithm uses LiDAR scan and odometry to keep track of where the robot is based on its current map and update the map with new information. Using a ROS program `gmapping`, we drove the robot with the potential field algorithm while it created the map. We then used that map for known map localization and path finding.

### Path Finding by A* Algorithm

Once we had a complete map, we implemented the A* algorithm to find the shortest path between two points. We planned to use that path for robot navigation in a known map and possibly later a dynamic map. The A* algorithm maintains a fronteir of values which are the locations that have not been explored yet but are possible to explore from the current explored area. Unlike the Djikstra's algorithm which moves outwardly in all directions equally until the goal is found, the A* algorithm uses a heuristic (in our case, smallest distance using vertical, horizontal, and diagonal movement) to estimate the after each point to get to the goal. This heuristic is used in conjunction with the current distance from start in prioritizing so paths moving away from the goal are less ideal than paths moving toward the goal. This allows the most efficient detection of the absolutely shortest path.

### Known Map Localization

We used another ROS library for known map localization known as Adaptive Monte Carlo Localization (AMCL) to detect the location of the robot based on its surroundings and odometry. The robot uses odometry to make an initial guess about its location then uses the Monte Carlo method to test similar values and compare to the LiDAR scan. Once the most accurate pose is found, it is used. We planned to use this pose array for path finding, but we were unable to finish because of issues with origin callibration and time constraints. It is also possible that we were correct algorithmically but that our parameters of physical control were not ideal.

### Future Work

Although we were unable to finish, we were able to detect the shortest path and attact the robot toward the path and goal while repelling the wall. However, although this worked in theory, the robot did not react as expected. We also struggled to coordinate origins and would have likely finished if more time had been available, but we were unable to find the bug which prevented the axes from aligning and allowign the robot to react to the correct displacement from the goal.

## Conclusions

The Robotic Control Systems course was a grand success. Even though we did not complete our final project, we were able to explore parallel computing in a different environment than most other computer science courses. The couse used a very effective project exploration style which allowed discovery without the need for many boring lectures and powerpoints. The course will be much more efficient next year when the robot is complete at the start of the course and the teacher has a more complete understanding of all the topics covered. The course may be the start to an interesting new system at GSSM which would make it unlike most other high schools if more students are allowed to share their summer research experiences or just their technical skills in general through independent study courses. I am glad to be a part of this educatino revolution. 
